#!/bin/bash
# Mock curl script for testing S3 operations

# Directory containing mock responses
RESPONSE_DIR="$(dirname "$0")/../data/responses"

# Parse curl arguments to determine what's being requested
OUTPUT_FILE=""
URL=""
IS_HEAD_REQUEST=false
IS_PUT_REQUEST=false
IS_DELETE_REQUEST=false
DATA_FILE=""

while [[ $# -gt 0 ]]; do
    case $1 in
        -o)
            OUTPUT_FILE="$2"
            shift 2
            ;;
        -I)
            IS_HEAD_REQUEST=true
            shift
            ;;
        -X)
            if [ "$2" = "PUT" ]; then
                IS_PUT_REQUEST=true
            elif [ "$2" = "DELETE" ]; then
                IS_DELETE_REQUEST=true
            fi
            shift 2
            ;;
        --data-binary)
            if [[ "$2" =~ ^@ ]]; then
                DATA_FILE="${2#@}"  # Remove @ prefix
            fi
            shift 2
            ;;
        -s|-S)
            shift
            ;;
        http*|https*)
            URL="$1"
            shift
            ;;
        *)
            shift
            ;;
    esac
done

# Extract the object key from the URL
# URL format: https://bucket.s3.amazonaws.com/key
if [[ "$URL" =~ /([^/]+)$ ]]; then
    KEY="${BASH_REMATCH[1]}"
    # URL encode the key for file lookup (space -> %20, etc.)
    ENCODED_KEY=$(printf '%s\n' "$KEY" | sed 's/ /%20/g')
else
    KEY=""
    ENCODED_KEY=""
fi

# Determine response file based on key
if [ "$IS_HEAD_REQUEST" = true ]; then
    # HEAD request - checking if object exists
    if [ -f "$RESPONSE_DIR/head_${ENCODED_KEY}" ]; then
        cat "$RESPONSE_DIR/head_${ENCODED_KEY}"
        exit 0
    else
        exit 22  # curl error code for 404
    fi
fi

# PUT request - upload object content
if [ "$IS_PUT_REQUEST" = true ]; then
    # Mock PUT success (HTTP 200) for any object with credentials
    # In real S3, this would require AWS signature authentication
    exit 0
fi

# DELETE request - delete object
if [ "$IS_DELETE_REQUEST" = true ]; then
    # Mock DELETE success (HTTP 204) for any object with credentials
    # In real S3, this would require AWS signature authentication
    # Simulate failure for certain test keys
    if [ "$KEY" = "delete_failure_test.txt" ]; then
        exit 22  # curl error code for HTTP error
    fi
    exit 0
fi

# GET request - return object content
if [ -n "$OUTPUT_FILE" ]; then
    # Special test cases for various scenarios
    if [ "$KEY" = "network_failure_test.txt" ]; then
        # Simulate network failure
        exit 7  # curl error code for couldn't connect to host
    elif [ "$KEY" = "timeout_test.txt" ]; then
        # Simulate timeout
        exit 28  # curl error code for operation timeout
    elif [ "$KEY" = "malformed_response.txt" ]; then
        # Special case for testing malformed XML responses
        cp "$RESPONSE_DIR/malformed.xml" "$OUTPUT_FILE"
        exit 0
    elif [ -f "$RESPONSE_DIR/${KEY}" ]; then
        # File exists - return its content
        cp "$RESPONSE_DIR/${KEY}" "$OUTPUT_FILE"
        exit 0
    else
        # File doesn't exist - return NoSuchKey error
        if [ -f "$RESPONSE_DIR/nosuchkey.xml" ]; then
            cp "$RESPONSE_DIR/nosuchkey.xml" "$OUTPUT_FILE"
        else
            # Fallback if nosuchkey.xml doesn't exist
            echo "<?xml version=\"1.0\" encoding=\"UTF-8\"?>" > "$OUTPUT_FILE"
            echo "<Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Key>$KEY</Key></Error>" >> "$OUTPUT_FILE"
        fi
        exit 0
    fi
fi

# Default: if we get here, it's an unsupported operation
echo "Mock curl: Unsupported operation" >&2
exit 1